{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms, models\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import PIL\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    def __init__(self, net, dim):\n",
    "        super(ResNet, self).__init__()\n",
    "        self.net = net.eval().cuda()\n",
    "        self.dim = dim\n",
    "        self.penult_layer = self.net._modules.get('avgpool')\n",
    "    \n",
    "    def forward(self, x):\n",
    "        output = self.get_embedding(self, x)\n",
    "        return output\n",
    "    \n",
    "    def get_embedding(self, x):\n",
    "        embedding = torch.cuda.FloatTensor(x.shape[0], self.dim, 1, 1).fill_(0)\n",
    "        def copy(m, i ,o):\n",
    "            embedding.copy_(o.data)\n",
    "        hook = self.penult_layer.register_forward_hook(copy)\n",
    "        self.net(x)\n",
    "        hook.remove()\n",
    "        return embedding.view(embedding.size()[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'data/Flickr'\n",
    "image_transform = transforms.Compose([\n",
    "    transforms.Resize((224,224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
    "image_data = ImageFolder(image_directory, transform = image_transform)\n",
    "image_from_idx = [i[0] for i in image_data.samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "269648"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(image_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_dataloader = DataLoader(image_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152 = ResNet(models.resnet152(pretrained=True), 2048)\n",
    "resnet18 = ResNet(models.resnet18(pretrained=True), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = []\n",
    "resnet18_feats = []\n",
    "resnet152_feats = []\n",
    "\n",
    "for batch_idx, (data, target) in enumerate(image_dataloader):\n",
    "    if not type(data) in (tuple, list):\n",
    "        data = (data,)\n",
    "    data = tuple(d.cuda() for d in data)\n",
    "    \n",
    "    embeddings_18 = resnet18.get_embedding(*data).detach().cpu()\n",
    "    embeddings_152 = resnet152.get_embedding(*data).detach().cpu()\n",
    "    for i in range(batch_size):\n",
    "        targets.append(int(target[i]))\n",
    "        resnet18_feats.append(embeddings_18[i].numpy())\n",
    "        resnet152_feats.append(embeddings_152[i].numpy())\n",
    "    if batch_idx and not batch_idx % 100:\n",
    "        np.save(\"data/nuswide_features/targets/batch_{}.npy\".format(str(batch_idx).zfill(5)), targets)\n",
    "        np.save(\"data/nuswide_features/resnet18/batch_{}.npy\".format(str(batch_idx).zfill(5)), resnet18_feats)\n",
    "        np.save(\"data/nuswide_features/resnet152/batch_{}.npy\".format(str(batch_idx).zfill(5)), resnet152_feats)\n",
    "        targets = []\n",
    "        resnet18_feats = []\n",
    "        resnet152_feats = []\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_idx = len(image_dataloader)\n",
    "np.save(\"data/nuswide_features/targets/batch_{}.npy\".format(str(batch_idx).zfill(5)), targets)\n",
    "np.save(\"data/nuswide_features/resnet18/batch_{}.npy\".format(str(batch_idx).zfill(5)), resnet18_feats)\n",
    "np.save(\"data/nuswide_features/resnet152/batch_{}.npy\".format(str(batch_idx).zfill(5)), resnet152_feats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
