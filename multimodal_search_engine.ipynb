{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Search Engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import os\n",
    "def time_elapsed(s):\n",
    "    '''\n",
    "    Function to establish baselines for time needed to setup a search engine\n",
    "    '''\n",
    "    print(\"Time Elapsed: {} seconds\".format(round(time.time() - s, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "\n",
    "import PIL\n",
    "import pickle\n",
    "import os\n",
    "import traceback\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "\n",
    "from search import SearchEngine\n",
    "from networks import FeatureExtractor\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize SearchEngine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_directory = './embeddings'\n",
    "search_engine = SearchEngine([\"text\", \"image\"], save_directory = save_directory, verbose = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_15 = pickle.load(open(\"pickles/models/entire_nuswide_model_15.p\", \"rb\"))\n",
    "search_engine.add_model(\n",
    "    name = \"ResNet152_15\", \n",
    "    modalities = [\"image\",\"text\"], \n",
    "    embedding_nets = [resnet152_15.modalityOneNet, resnet152_15.modalityTwoNet],\n",
    "    input_dimensions= [(2048,), (300,)], \n",
    "    output_dimension = 64, \n",
    "    desc = \"ResNet152 trained with 15 epochs\")\n",
    "search_engine.models[\"ResNet152_15\"].add_preprocessing(\"image\", FeatureExtractor(\"resnet152\").get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet152_5 = pickle.load(open(\"pickles/models/entire_nuswide_model_5.p\", \"rb\"))\n",
    "search_engine.add_model(\n",
    "    name = \"ResNet152_5\", \n",
    "    modalities = [\"image\",\"text\"], \n",
    "    embedding_nets = [resnet152_5.modalityOneNet, resnet152_5.modalityTwoNet],\n",
    "    input_dimensions= [(2048,), (300,)], \n",
    "    output_dimension = 64, \n",
    "    desc = \"ResNet152 trained with 5 epochs\")\n",
    "search_engine.models[\"ResNet152_5\"].add_preprocessing(\"image\", FeatureExtractor(\"resnet152\").get_embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet18_5 = pickle.load(open(\"pickles/models/entire_nuswide_model_5-18.p\", \"rb\"))\n",
    "search_engine.add_model(\n",
    "    name = \"ResNet18_5\", \n",
    "    modalities = [\"image\",\"text\"], \n",
    "    embedding_nets = [resnet18_5.modalityOneNet, resnet18_5.modalityTwoNet],\n",
    "    input_dimensions= [(512,), (300,)], \n",
    "    output_dimension = 64, \n",
    "    desc = \"ResNet18 trained with 5 epochs\")\n",
    "search_engine.models[\"ResNet18_5\"].add_preprocessing(\"image\", FeatureExtractor(\"resnet18\").get_embedding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_directory = 'data/Flickr'\n",
    "image_from_idx = [i[0] for i in ImageFolder(image_directory).samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Elapsed: 23.2125 seconds\n"
     ]
    }
   ],
   "source": [
    "s = time.time()\n",
    "\n",
    "image_data18 = np.array([])\n",
    "directory_18 = \"data/nuswide_features/resnet18/\"\n",
    "filenames = sorted([\"{}/{}\".format(directory_18, filename) \n",
    "                    for filename in os.listdir(directory_18) if filename[-3:] == \"npy\"])\n",
    "for filename in filenames:\n",
    "    image_data18 = np.append(image_data18, np.load(filename,))\n",
    "image_data18.resize(len(image_data18) // 512, 512)\n",
    "image_data18 = torch.from_numpy(image_data18).cuda().float()\n",
    "time_elapsed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "\n",
    "image_data152 = np.array([])\n",
    "directory_152 = \"data/nuswide_features/resnet152/\"\n",
    "filenames = sorted([\"{}/{}\".format(directory_152, filename) \n",
    "                    for filename in os.listdir(directory_152) if filename[-3:] == \"npy\"])\n",
    "for filename in filenames:\n",
    "    image_data152 = np.append(image_data152, np.load(filename).astype('float32'))\n",
    "image_data152.resize(len(image_data152) // 2048, 2048)\n",
    "image_data152 = torch.from_numpy(image_data152).cuda().float()\n",
    "\n",
    "time_elapsed(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = time.time()\n",
    "\n",
    "FAST_TEXT = pickle.load(open(\"pickles/word_embeddings/word_embeddings_tensors.p\", \"rb\"))\n",
    "fast_text = FAST_TEXT\n",
    "text_from_idx = [None] * len(fast_text)\n",
    "text_data = [None] * len(fast_text)\n",
    "for idx, (key, value) in enumerate(fast_text.items()):\n",
    "    text_from_idx[idx] = key\n",
    "    text_data[idx] = (value, idx)\n",
    "\n",
    "time_elapsed(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build DataLoaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "image18_dataloader = DataLoader(image_data18, batch_size = batch_size)\n",
    "image152_dataloader = DataLoader(image_data152, batch_size = batch_size)\n",
    "text_dataloader = DataLoader(text_data, batch_size = batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.add_dataset(\n",
    "    name = \"nus-wide_18\", \n",
    "    data = image18_dataloader, \n",
    "    targets = image_from_idx, \n",
    "    modality = \"image\", \n",
    "    dimension = (512,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.add_dataset(\n",
    "    name = \"nus-wide_152\", \n",
    "    data = image152_dataloader, \n",
    "    targets = image_from_idx, \n",
    "    modality = \"image\", \n",
    "    dimension = (2048,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.add_dataset(\n",
    "    name = \"fast_text\", \n",
    "    data = text_dataloader, \n",
    "    targets = text_from_idx, \n",
    "    modality = \"text\", \n",
    "    dimension = (300,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.build_index(\n",
    "    dataset_name = \"nus-wide_18\",\n",
    "    model_name = \"ResNet18_5\",\n",
    "    binarized = False,\n",
    "    load_embeddings = False,\n",
    "    step_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.build_index(\n",
    "    dataset_name = \"nus-wide_152\",\n",
    "    model_name = \"ResNet152_5\",\n",
    "    binarized = False,\n",
    "    load_embeddings = False,\n",
    "    step_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.build_index(\n",
    "    dataset_name = \"nus-wide_152\",\n",
    "    model_name = \"ResNet152_15\",\n",
    "    binarized = False,\n",
    "    load_embeddings = False,\n",
    "    step_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.build_index(\n",
    "    dataset_name = \"fast_text\",\n",
    "    model_name = \"ResNet18_5\",\n",
    "    binarized = False,\n",
    "    load_embeddings = False,\n",
    "    step_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.build_index(\n",
    "    dataset_name = \"fast_text\",\n",
    "    model_name = \"ResNet152_5\",\n",
    "    binarized = False,\n",
    "    load_embeddings = False,\n",
    "    step_size = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine.build_index(\n",
    "    dataset_name = \"fast_text\",\n",
    "    model_name = \"ResNet152_15\",\n",
    "    binarized = False,\n",
    "    load_embeddings = False,\n",
    "    step_size = 1000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch_p36]",
   "language": "python",
   "name": "conda-env-pytorch_p36-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
